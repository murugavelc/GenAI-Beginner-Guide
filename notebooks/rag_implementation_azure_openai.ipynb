{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf91cf4e",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) Implementation with Azure OpenAI\n",
    "\n",
    "This notebook demonstrates a basic RAG pipeline using Azure OpenAI and a simple in-memory document store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db85ea5",
   "metadata": {},
   "source": [
    "## 1. Setup: Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39018354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI SDK if not already installed\n",
    "!pip install openai tiktoken --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9da219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set your Azure OpenAI credentials\n",
    "os.environ['AZURE_OPENAI_KEY'] = 'your-azure-openai-key'\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = 'your-azure-endpoint-url'\n",
    "os.environ['AZURE_OPENAI_MODEL'] = 'gpt-35-turbo'  # or your deployed model name\n",
    "os.environ['AZURE_OPENAI_API_VERSION'] = '2024-02-15-preview'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182d2d5",
   "metadata": {},
   "source": [
    "## 2. Create a Simple Document Store\n",
    "\n",
    "We'll use a Python dictionary to simulate a document store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5feaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example document store\n",
    "documents = {\n",
    "    'doc1': 'Large Language Models (LLMs) are AI models trained on vast text data.',\n",
    "    'doc2': 'RAG combines LLMs with retrieval from external sources for better answers.',\n",
    "    'doc3': 'Azure OpenAI provides enterprise-grade LLM APIs.'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c87a7",
   "metadata": {},
   "source": [
    "## 3. Retrieve Relevant Documents\n",
    "\n",
    "For simplicity, we'll use keyword matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, docs):\n",
    "    return [text for text in docs.values() if any(word.lower() in text.lower() for word in query.split())]\n",
    "\n",
    "query = 'What is RAG?'\n",
    "retrieved_docs = retrieve(query, documents)\n",
    "print('Retrieved:', retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82381205",
   "metadata": {},
   "source": [
    "## 4. Generate an Answer with Azure OpenAI\n",
    "\n",
    "We combine the query and retrieved docs as context for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '\\n'.join(retrieved_docs)\n",
    "prompt = f'Context: {context}\\n\\nQuestion: {query}\\nAnswer:'\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=os.environ['AZURE_OPENAI_MODEL'],\n",
    "    api_key=os.environ['AZURE_OPENAI_KEY'],\n",
    "    api_base=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "print(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d88d44",
   "metadata": {},
   "source": [
    "## 5. Experiment: Try Your Own Query!\n",
    "\n",
    "Change the query and see how the RAG pipeline responds."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
